{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Files Processing Pipeline\n",
    "The goal of this notebook is to present a complete pipeline of transforming annual reports from PDF files to tabular dataset. The transformed dataset will be useful for downstream natural langauage processing tasks, including text classification, topic modelling, etc.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* [1. Required Libraries](#1.)\n",
    "* [2. Parsing PDF](#2.)\n",
    "    * [2.1. Parsing PDF Files in Batch](#2.1.)\n",
    "    * [2.2. Aggregate Text Files](#2.2.)\n",
    "    * [2.3. File Update](#2.3.)\n",
    "    * [2.4. Read Jason File into Pandas Dataframe](#2.4.)\n",
    "    * [2.5. Table of Contents (TOC) Parsing](#2.5.)\n",
    "        * [2.5.1. Expand Page List](#2.5.1.)\n",
    "        * [2.5.2. Locate TOC Page](#2.5.2.)\n",
    "        * [2.5.3. Extract TOC](#2.5.3.)\n",
    "        * [2.5.4. Examples of Manual Editing](#2.5.4.)\n",
    "            * [a) Change the whole TOC manually directly](#2.5.4.a.)\n",
    "            * [b) Change the parser mode and matcher mode](#2.5.4.b.)\n",
    "        * [2.5.5. Assign Headings](#2.5.5.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Required Libraries <a class=\"anchor\" id=\"1.\"></a>\n",
    "The core module pdfparser is built upon the following libraries:\n",
    "* tika (Java 7+ is required for this library)\n",
    "* pytesseract (tesseract is required for this library)\n",
    "* beatifulsoup\n",
    "* pdf2image\n",
    "* opencv\n",
    "* pandas\n",
    "* numpy \n",
    "\n",
    "Other libraries needed are:\n",
    "* os\n",
    "* json\n",
    "* re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pdfparser as Parser \n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Parsing PDF <a class=\"anchor\" id=\"2.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Parsing PDF Files in Batch <a class=\"anchor\" id=\"2.1.\"></a>\n",
    "\n",
    "Put the PDF files in the main folder, in this case the Annual_Report folder, and the following code will help you loop through all PDF files and try to parse them. The parser will take the raw PDF and extract its text content. The parser will also automatically write the text data of a PDF file into a txt file to save progress of the transformation since parsing files could take some time.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barclays_Plc_Annual_Report_2016.pdf\n",
      "parsing text-formatted pdf file\n",
      "parsing finished:Barclays_Plc_Annual_Report_2016\n",
      "Barclays_Plc_Annual_Report_2017.pdf\n",
      "parsing text-formatted pdf file\n",
      "parsing finished:Barclays_Plc_Annual_Report_2017\n",
      "Barclays_Plc_Annual_Report_2018.pdf\n",
      "parsing text-formatted pdf file\n",
      "parsing finished:Barclays_Plc_Annual_Report_2018\n",
      "Barclays_Plc_Annual_Report_2019.pdf\n",
      "parsing text-formatted pdf file\n",
      "parsing finished:Barclays_Plc_Annual_Report_2019\n"
     ]
    }
   ],
   "source": [
    "# the folder that holds all initial annual reports\n",
    "parent_path = \".\\Data\\Reports\\Annual_Report\" \n",
    "all_path = os.listdir(parent_path) #list of file paths\n",
    "pdf_list = [file for file in all_path if file[-3:]=='pdf']\n",
    "os.chdir(parent_path)\n",
    "\n",
    "#Parse the PDF files and write page contents into text files\n",
    "# the txt files will be stored under the parent_path  \n",
    "for file_path in pdf_list:\n",
    "    print(file_path)\n",
    "    Parser.pdfparser(file_path,delete_existing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2. Aggregate Text Files <a class=\"anchor\" id=\"2.2.\"></a>\n",
    "The text files will be dumped into one json file. This step makes it easier to transfer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text=[]\n",
    "txt_list = [file for file in all_path if file[-3:]=='txt']\n",
    "for file_path in txt_list:\n",
    "    # Reads the text file and stores data to dictionary\n",
    "    all_text.append(Parser.text_to_dict(file_path)) \n",
    "with open(\"raw_text_all.json\",\"w\") as f:\n",
    "    json.dump(all_text,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3. File Update <a class=\"anchor\" id=\"2.3.\"></a>\n",
    "In case we have new files to process, we can put them in a separate folder to avoid extracting data from the processed files again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing image-formatted pdf file\n",
      "Folder of Aspen_Insurance_UK_Ltd_Annual_Report_2019.pdf already exsits\n",
      "Delete the exisiting folder\n",
      "parsing finished:Aspen_Insurance_UK_Ltd_Annual_Report_2019\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#New annual report updates\n",
    "os.chdir(\"../../..\")\n",
    "parent_path = \".\\Data\\Reports\\Annual_Report_Updates\" \n",
    "all_path = os.listdir(parent_path)\n",
    "pdf_list = [file for file in all_path if file[-3:]=='pdf']\n",
    "os.chdir(parent_path)\n",
    "for file_path in pdf_list:\n",
    "    Parser.pdfparser(file_path,delete_existing=True)\n",
    "\n",
    "all_text=[]\n",
    "txt_list = [file for file in all_path if file[-3:]=='txt']\n",
    "print(len(txt_list))\n",
    "for file_path in txt_list:\n",
    "    all_text.append(Parser.text_to_dict(file_path))\n",
    "with open(\"raw_text_all.json\",\"w\") as f:\n",
    "    json.dump(all_text,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4. Read Json File into Pandas Dataframe <a class=\"anchor\" id=\"2.4.\"></a>\n",
    "To facilitate downstream text analysis/machine learning tasks, we can now read the transformed json file into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main json file\n",
    "os.chdir(\"../../..\")\n",
    "parent_path = \".\\Data\\Reports\\Annual_Report\"  \n",
    "os.chdir(parent_path)\n",
    "df = pd.read_json('raw_text_all.json','records')\n",
    "\n",
    "# Generate 4 more columns to help us evaluate the results\n",
    "\n",
    "df['row']=df.index\n",
    "df['total_page'] = df.raw_text.apply(lambda x: len(x))\n",
    "\n",
    "# As the structure of file name may vary, we didn't include generating columns of firm_name and year in Parser  \n",
    "df['firm_name'] = df.file_name.apply(lambda x:\n",
    "                               re.findall(r'.+(?=_Annual_Report)',x)[0])\n",
    "df['year'] = df.file_name.apply(lambda x:\n",
    "                         re.findall(r'.{4}(?=_text)',x)[0])\n",
    "\n",
    "\n",
    "#Updated file\n",
    "\n",
    "os.chdir(\"../../..\")\n",
    "parent_path = \".\\Data\\Reports\\Annual_Report_Updates\"  \n",
    "os.chdir(parent_path)\n",
    "df_update = pd.read_json('raw_text_all.json','records')\n",
    "df_update['row']=df_update.index\n",
    "df_update['total_page'] = df_update.raw_text.apply(lambda x: len(x))\n",
    "df_update['firm_name'] = df_update.file_name.apply(lambda x:\n",
    "                               re.findall(r'.+(?=_Annual_Report)',x)[0])\n",
    "df_update['year'] = df_update.file_name.apply(lambda x:\n",
    "                         re.findall(r'.{4}(?=_text)',x)[0])\n",
    "\n",
    "\n",
    "# Update df with df_update (must reset column row with new index)\n",
    "df_new = df[~df['file_name'].isin(df_update['file_name'])].copy()\n",
    "df_new = pd.concat([df_new,df_update],ignore_index=True,sort=False)\n",
    "df_new['row'] = df_new.index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Table of Contents (TOC) Parsing <a class=\"anchor\" id=\"2.5.\"></a>\n",
    "\n",
    "Having a table of contents simplifies the navigation through the reports, although it is not necessary for all nlp tasks. This section demonstrates steps to achieve this goal with our pdfparser module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1. Expand Page List <a class=\"anchor\" id=\"2.5.1.\"></a>\n",
    "Previously the pages of a file are stored in a list, we expand this list to make it easier for the following processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>bookmark</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>source_type</th>\n",
       "      <th>total_page</th>\n",
       "      <th>firm_name</th>\n",
       "      <th>year</th>\n",
       "      <th>page_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barclays_Plc_Annual_Report_2016_text</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\nBarclays PLC\\nAnnual Report 2016\\n\\nBuilding...</td>\n",
       "      <td>Text</td>\n",
       "      <td>380</td>\n",
       "      <td>Barclays_Plc</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barclays_Plc_Annual_Report_2016_text</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\nThe Detailed Report\\nWithin the Annual Repor...</td>\n",
       "      <td>Text</td>\n",
       "      <td>380</td>\n",
       "      <td>Barclays_Plc</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barclays_Plc_Annual_Report_2016_text</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\nhome.barclays/annualreport Barclays PLC Annu...</td>\n",
       "      <td>Text</td>\n",
       "      <td>380</td>\n",
       "      <td>Barclays_Plc</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barclays_Plc_Annual_Report_2016_text</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\n02 • Barclays PLC Annual Report 2016 home.ba...</td>\n",
       "      <td>Text</td>\n",
       "      <td>380</td>\n",
       "      <td>Barclays_Plc</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays_Plc_Annual_Report_2016_text</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\nhome.barclays/annualreport Barclays PLC Annu...</td>\n",
       "      <td>Text</td>\n",
       "      <td>380</td>\n",
       "      <td>Barclays_Plc</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              file_name bookmark  \\\n",
       "0  Barclays_Plc_Annual_Report_2016_text       []   \n",
       "1  Barclays_Plc_Annual_Report_2016_text       []   \n",
       "2  Barclays_Plc_Annual_Report_2016_text       []   \n",
       "3  Barclays_Plc_Annual_Report_2016_text       []   \n",
       "4  Barclays_Plc_Annual_Report_2016_text       []   \n",
       "\n",
       "                                            raw_text source_type  total_page  \\\n",
       "0  \\nBarclays PLC\\nAnnual Report 2016\\n\\nBuilding...        Text         380   \n",
       "1  \\nThe Detailed Report\\nWithin the Annual Repor...        Text         380   \n",
       "2  \\nhome.barclays/annualreport Barclays PLC Annu...        Text         380   \n",
       "3  \\n02 • Barclays PLC Annual Report 2016 home.ba...        Text         380   \n",
       "4  \\nhome.barclays/annualreport Barclays PLC Annu...        Text         380   \n",
       "\n",
       "      firm_name  year  page_number  \n",
       "0  Barclays_Plc  2016            1  \n",
       "1  Barclays_Plc  2016            2  \n",
       "2  Barclays_Plc  2016            3  \n",
       "3  Barclays_Plc  2016            4  \n",
       "4  Barclays_Plc  2016            5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Expand dataframe\n",
    "#each row of the dataframe now contains only the information of one page\n",
    "\n",
    "df_expanded = Parser.expand_pagelist(df_new)\n",
    "df_expanded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2. Locate TOC Page <a class=\"anchor\" id=\"2.5.2.\"></a>\n",
    "To parse the toc of a file, we need to first locate its position. The pdfparser will do the tasks based on the text structure and standard heading examples. If the pdfparser can't not find the TOC, you can always input the acutual number by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the gold standard headings,\n",
    "# the standard are used to improve the parsing results,\n",
    "# especially for image PDF. You can add more headings as you like.\n",
    "os.chdir(\"../../..\")\n",
    "standard_headings = Parser.headings_preprocessor('.\\Data\\standard_headings.xlsx')\n",
    "\n",
    "# locate toc page, the final results are in the column 'toc_page'\n",
    "df_toc = Parser.find_toc_page(df_expanded,standard_headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the toc page number is nan, need to manually check and modification of the result\n",
    "for index,row in df_toc[pd.isna(df_toc['toc_page'])].iterrows():\n",
    "    print(index)\n",
    "    manual_check = input('''Please input where the Table of Content occurs, \n",
    "                         if no Table of Contents exits press Enter directly:''')\n",
    "    try:\n",
    "        df_toc.at[index,'toc_page'] = int(manual_check)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.3. Extract TOC <a class=\"anchor\" id=\"2.5.3.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_type</th>\n",
       "      <th>total_page</th>\n",
       "      <th>firm_name</th>\n",
       "      <th>year</th>\n",
       "      <th>toc_page</th>\n",
       "      <th>toc_headings_candidate</th>\n",
       "      <th>method</th>\n",
       "      <th>indexed_page_dict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barclays_Plc_Annual_Report_2016_text</th>\n",
       "      <td>Text</td>\n",
       "      <td>380</td>\n",
       "      <td>Barclays_Plc</td>\n",
       "      <td>2016</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[(2, chairman letter), (4, chief executive rev...</td>\n",
       "      <td>loo_par_auto</td>\n",
       "      <td>{4: (2, 'chairman letter'), 6: (4, 'chief exec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barclays_Plc_Annual_Report_2017_text</th>\n",
       "      <td>Text</td>\n",
       "      <td>328</td>\n",
       "      <td>Barclays_Plc</td>\n",
       "      <td>2017</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(2, chairman letter), (4, chief executive rev...</td>\n",
       "      <td>str_par_str_mat</td>\n",
       "      <td>{4: (2, 'chairman letter'), 6: (4, 'chief exec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barclays_Plc_Annual_Report_2018_text</th>\n",
       "      <td>Text</td>\n",
       "      <td>364</td>\n",
       "      <td>Barclays_Plc</td>\n",
       "      <td>2018</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(48, directors report), (93, people), (99, re...</td>\n",
       "      <td>str_par_loo_mat</td>\n",
       "      <td>{5: (1000, 'strategic report'), 6: (1000, 'gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barclays_Plc_Annual_Report_2019_text</th>\n",
       "      <td>Text</td>\n",
       "      <td>344</td>\n",
       "      <td>Barclays_Plc</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(2, business profile), (4, chairman introduct...</td>\n",
       "      <td>str_par_auto</td>\n",
       "      <td>{4: (2, 'business profile'), 6: (4, 'chairman ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspen_Insurance_UK_Ltd_Annual_Report_2019_text</th>\n",
       "      <td>Image</td>\n",
       "      <td>58</td>\n",
       "      <td>Aspen_Insurance_UK_Ltd</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[(1000, the company), (1000, strategic report)...</td>\n",
       "      <td>str_par_loo_mat</td>\n",
       "      <td>{3: (1000, 'the company'), 4: (1000, 'strategi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               source_type  total_page  \\\n",
       "file_name                                                                \n",
       "Barclays_Plc_Annual_Report_2016_text                  Text         380   \n",
       "Barclays_Plc_Annual_Report_2017_text                  Text         328   \n",
       "Barclays_Plc_Annual_Report_2018_text                  Text         364   \n",
       "Barclays_Plc_Annual_Report_2019_text                  Text         344   \n",
       "Aspen_Insurance_UK_Ltd_Annual_Report_2019_text       Image          58   \n",
       "\n",
       "                                                             firm_name  year  \\\n",
       "file_name                                                                      \n",
       "Barclays_Plc_Annual_Report_2016_text                      Barclays_Plc  2016   \n",
       "Barclays_Plc_Annual_Report_2017_text                      Barclays_Plc  2017   \n",
       "Barclays_Plc_Annual_Report_2018_text                      Barclays_Plc  2018   \n",
       "Barclays_Plc_Annual_Report_2019_text                      Barclays_Plc  2019   \n",
       "Aspen_Insurance_UK_Ltd_Annual_Report_2019_text  Aspen_Insurance_UK_Ltd  2019   \n",
       "\n",
       "                                                toc_page  \\\n",
       "file_name                                                  \n",
       "Barclays_Plc_Annual_Report_2016_text                 2.0   \n",
       "Barclays_Plc_Annual_Report_2017_text                 3.0   \n",
       "Barclays_Plc_Annual_Report_2018_text                 3.0   \n",
       "Barclays_Plc_Annual_Report_2019_text                 3.0   \n",
       "Aspen_Insurance_UK_Ltd_Annual_Report_2019_text       2.0   \n",
       "\n",
       "                                                                           toc_headings_candidate  \\\n",
       "file_name                                                                                           \n",
       "Barclays_Plc_Annual_Report_2016_text            [(2, chairman letter), (4, chief executive rev...   \n",
       "Barclays_Plc_Annual_Report_2017_text            [(2, chairman letter), (4, chief executive rev...   \n",
       "Barclays_Plc_Annual_Report_2018_text            [(48, directors report), (93, people), (99, re...   \n",
       "Barclays_Plc_Annual_Report_2019_text            [(2, business profile), (4, chairman introduct...   \n",
       "Aspen_Insurance_UK_Ltd_Annual_Report_2019_text  [(1000, the company), (1000, strategic report)...   \n",
       "\n",
       "                                                         method  \\\n",
       "file_name                                                         \n",
       "Barclays_Plc_Annual_Report_2016_text               loo_par_auto   \n",
       "Barclays_Plc_Annual_Report_2017_text            str_par_str_mat   \n",
       "Barclays_Plc_Annual_Report_2018_text            str_par_loo_mat   \n",
       "Barclays_Plc_Annual_Report_2019_text               str_par_auto   \n",
       "Aspen_Insurance_UK_Ltd_Annual_Report_2019_text  str_par_loo_mat   \n",
       "\n",
       "                                                                                indexed_page_dict  \n",
       "file_name                                                                                          \n",
       "Barclays_Plc_Annual_Report_2016_text            {4: (2, 'chairman letter'), 6: (4, 'chief exec...  \n",
       "Barclays_Plc_Annual_Report_2017_text            {4: (2, 'chairman letter'), 6: (4, 'chief exec...  \n",
       "Barclays_Plc_Annual_Report_2018_text            {5: (1000, 'strategic report'), 6: (1000, 'gov...  \n",
       "Barclays_Plc_Annual_Report_2019_text            {4: (2, 'business profile'), 6: (4, 'chairman ...  \n",
       "Aspen_Insurance_UK_Ltd_Annual_Report_2019_text  {3: (1000, 'the company'), 4: (1000, 'strategi...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column to store potenrial headings\n",
    "df_expanded = Parser.extract_potential_headings(df_expanded)\n",
    "\n",
    "# Auto matching\n",
    "df_toc_final = Parser.auto_parser_matcher(df_expanded,df_toc,standard_headings)\n",
    "df_toc_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.4. Examples of Manual Editing <a class=\"anchor\" id=\"2.5.4.\"></a>\n",
    "As for the cases where certain results are not satisfying, we can use manual editing and following is an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Change the whole TOC manually directly <a class=\"anchor\" id=\"2.5.4.a.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example only\n",
    "# file_name =  '.\\Data\\Reports\\Annual_Report_Updates\\Aspen_Insurance_UK_Ltd_Annual_Report_2019_text'\n",
    "# dict_ = {2:(2,'strategic report'),6:(6,'directors report'),\n",
    "#        7:(7,'statement of directors responsibilities'),\n",
    "#        8:(8,'independent auditors report'),\n",
    "#        13:(13,'financial statements'),\n",
    "#        17:(17,'notes to financial statement'),\n",
    "#        39:(39,'risk related disclosure'),\n",
    "#        47:(47,'others')}\n",
    "\n",
    "# df_toc_final = Parser.manual_editor(df_expanded,df_toc_final,file_name,standard_headings,parser_auto=dict_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Change the parser mode and matcher mode <a class=\"anchor\" id=\"2.5.4.b.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example only: change the parser mode and matcher mode for image pdf\n",
    "# file_name = '.\\Data\\Reports\\Annual_Report\\Barclays_Plc_Annual_Report_2016_text'\n",
    "# df_toc_final2 = Parser.manual_editor(df_expanded,df_toc_final,file_name,standard_headings,parser='str',matcher='loose')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.5. Assign Headings to Pages  <a class=\"anchor\" id=\"2.5.5.\"></a>\n",
    "Now we can assign headings to the corresponding page according to the extracted toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded = Parser.retrieve_headings(df_expanded,df_toc_final)\n",
    "df_sections = df_expanded.loc[:,['file_name','firm_name','year','source_type',\n",
    "                                 'total_page','page_number','raw_text','headings']].copy()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f80bc96eb627a92d8e588de52d70d9edbf0c0e58da7635fdb338a2906399ba2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
